{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"PcLyYHzlUkIC"},"source":["# Sentence Reconstruction\n","\n","Name and ID: Angelo Galavotti 0001103433\n","\n","This notebook contains the submission for the Deep Learning of 14/06/2023. \n","\n","### Description of the task\n","- Take in input a __sequence of words__ corresponding to a random permutation of a given english sentence, and __reconstruct the original sentence__.\n","\n","- The output can be either produced in a single shot, or through an iterative (autoregressive) loop generating a single token at a time.\n","\n","CONSTRAINTS:\n","\n","- No pretrained model can be used.\n","- The neural network models should have __less than 20M parameters__.\n","\n","## Solution approach\n","To compute a valid solution, I've decided to adopt a model which makes use of Transformers and Multi-head attention.\n","\n","In this notebook, I will describe the most important steps of the whole approach. Additionally, at the end of the notebook, I will briefly state about my previous attempts. \n","\n","----"]},{"cell_type":"markdown","metadata":{"id":"adQLgtOeZi0s"},"source":["# Downloading the dataset"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-06-10T14:47:13.810746Z","iopub.status.busy":"2023-06-10T14:47:13.810044Z","iopub.status.idle":"2023-06-10T14:47:38.893504Z","shell.execute_reply":"2023-06-10T14:47:38.891903Z","shell.execute_reply.started":"2023-06-10T14:47:13.810712Z"},"executionInfo":{"elapsed":36944,"status":"ok","timestamp":1686324990717,"user":{"displayName":"Angelo Galavotti (turtleturd)","userId":"13066918554475446773"},"user_tz":-120},"id":"4N0Wuo5KUL5x","outputId":"d0b17bb5-100f-46e6-9039-19857c6d426c","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (9.0.0)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.1.1)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.28.2)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.64.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.5.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.14.1)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.0)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.4.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.5.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n","Collecting dill (from datasets)\n","  Using cached dill-0.3.6-py3-none-any.whl (110 kB)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: dill\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.1.1\n","    Uninstalling dill-0.3.1.1:\n","      Successfully uninstalled dill-0.3.1.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\n","pymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\n","pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.10.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed dill-0.3.6\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: apache-beam in /opt/conda/lib/python3.10/site-packages (2.46.0)\n","Requirement already satisfied: protobuf<4,>3.12.2 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (3.20.3)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (1.7)\n","Requirement already satisfied: orjson<4.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (3.8.12)\n","Collecting dill<0.3.2,>=0.3.1.1 (from apache-beam)\n","  Using cached dill-0.3.1.1-py3-none-any.whl\n","Requirement already satisfied: cloudpickle~=2.2.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (2.2.1)\n","Requirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (1.7.4)\n","Requirement already satisfied: fasteners<1.0,>=0.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (0.18)\n","Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (1.51.1)\n","Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (2.7.0)\n","Requirement already satisfied: httplib2<0.22.0,>=0.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (0.21.0)\n","Requirement already satisfied: numpy<1.25.0,>=1.14.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (1.23.5)\n","Requirement already satisfied: objsize<0.7.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (0.6.1)\n","Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (3.13.0)\n","Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (1.22.2)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (1.4.2)\n","Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (2.8.2)\n","Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (2023.3)\n","Requirement already satisfied: regex>=2020.6.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (2023.5.5)\n","Requirement already satisfied: requests<3.0.0,>=2.24.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (2.28.2)\n","Requirement already satisfied: typing-extensions>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (4.5.0)\n","Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (0.19.0)\n","Requirement already satisfied: pyarrow<10.0.0,>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (9.0.0)\n","Requirement already satisfied: docopt in /opt/conda/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam) (0.6.2)\n","Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam) (1.16.0)\n","Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<0.22.0,>=0.8->apache-beam) (3.0.9)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam) (2.1.1)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam) (2023.5.7)\n","Installing collected packages: dill\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.6\n","    Uninstalling dill-0.3.6:\n","      Successfully uninstalled dill-0.3.6\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","multiprocess 0.70.14 requires dill>=0.3.6, but you have dill 0.3.1.1 which is incompatible.\n","pathos 0.3.0 requires dill>=0.3.6, but you have dill 0.3.1.1 which is incompatible.\n","pymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\n","pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.10.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed dill-0.3.1.1\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install datasets\n","!pip3 install apache-beam"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T14:47:38.896788Z","iopub.status.busy":"2023-06-10T14:47:38.896380Z","iopub.status.idle":"2023-06-10T14:47:38.903313Z","shell.execute_reply":"2023-06-10T14:47:38.902223Z","shell.execute_reply.started":"2023-06-10T14:47:38.896746Z"},"id":"INZIMG8itLHh","trusted":true},"outputs":[],"source":["from random import Random\n","\n","# Instantiate the Random instance with random seed = 42 to ensure reproducibility\n","randomizer = Random(42)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T14:47:38.905759Z","iopub.status.busy":"2023-06-10T14:47:38.904999Z","iopub.status.idle":"2023-06-10T14:47:50.357010Z","shell.execute_reply":"2023-06-10T14:47:50.355829Z","shell.execute_reply.started":"2023-06-10T14:47:38.905727Z"},"id":"jRVmQCKdRb54","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: gdown in /opt/conda/lib/python3.10/site-packages (4.7.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.0)\n","Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.28.2)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.64.1)\n","Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\n","Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2.1.1)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.5.7)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install gdown\n","from keras.preprocessing.text import Tokenizer\n","from keras.utils import to_categorical, pad_sequences\n","import numpy as np \n","import pickle\n","import gdown\n","import random"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":266,"referenced_widgets":["fe67467be06a4c00872c054f062b51be","4998c41faaff4764b0ff4e8e4215e303","b960f44010e840a3a41975adbb4fcb87","56cd0d1c2d1d45b88234f75ac59d028f","4b4d882394a94f0aaa580f9040e89710","59875cf6636947df9597b2eadca89607","ceb18602d4d942c188b40309b02a7121","be342c8725bc45df80c0b4645028453c","96d90639bd464b989a030ad8e203ab91","ab575a21d9e54d9fa3f218ba2937d33d","5732418d14a24287a524fbb74dfb8bd6","b959770d35844c56afa4d8cabc229120","451abe63d0084d7f9415e15efd33d931","e67ecd1c2d2c4bd09b69a2ecae966d00","717bca4b98ee4577aa6d23d93271de30","6325f02f746a4b50a2ff6a5ae9ea3ba1","53f4ddf490db4b76b9956e3f6ebde211","070b38411aca4d61b27e92ff013e54f5","947ee1e30b9d4c0fa70481e7095d6418","5064e382022d4e8b97f19a6547fc1223","3df2eb52e166436e8963c644518768cc","25283ef15961416fa6d21875ea0bce97","d9bb2f2922504071bccc82fd57cc34e6","a48249ce08784da38c7eb20c04c85cd1","f975205ff20e482b8850b51bdcaefe1d","a96af45ce82c4a8f9867d44dbde6600e","35fb8d8b4d464afb9e86e8734e686c6d","7d43bb04fefa4589a356665490fa74ef","ed355d7b2ab54bdbada7ea9862826a7c","00159a7140a845ff90d51f0b380e2561","4e8d2888553948e5b678ef9ce61d9e0b","f99e102cce8548dfaacd0c8a3f5f7b68","02fe7f98f5084e71865c29839a9eb485","54f6c2774a2d43739754730ba19d0e18","be36d1bc0e924bad872ea4a9d103f3c2","f6bdf604c22d47e583328d53771c02db","26b6c357556240848527b759e6916ad4","1719c3c00e8148e3bed47fa7fe235068","8b218b93aa7b4dd2b9c0b84345deffcc","bff0c2ee92f04b0b8f89644c7dc360ba","e49a61dae69644c7b361cef046df71c3","b6bb330ba0254b2dbb415392553f7c5b","cedea08ec76d4f5c9936f2839e5ecd6e","b05587382e6a441dad04c47c7a37afa3","e455328f873a438b99b485c2649e0109","965c1953e254441e86dce8337baccc95","6d45feda283e46e2877370f3b0b84d2d","cfdeecd47cb44a1a9af9b48770f08846","b5f89a9c0d6f427fadfb802dba48a38e","b43aa0e9e21d4da0a92da714f97a2536","5f33bc1eb44141528d91eddf47d4ae4d","f6e11afe33fa4473bc0e5fd0c1b6de54","a5d5e0994ea3465498b5e94b9fd37168","ced176bcea814fdfbe915340d327ebc2","f94d31095cd34f4caa045c51898a2632","17fca631b9e845729fb1e3d00ceff408","0fe9606754f846dca2a9529c1c23afd9","053255074eaf4e6b981d3b6365b5043f","1e456f0222cd4152a8603e2f4bef9f71","3471275787d848c7a54b53ef672d1d74","7f45e946fbf34b49a93b1816b36ca060","978e8855a74b42caa003ce41eb3b8360","39cd88457a5b4825b2d714337617dab5","f24d7234a8fc47bba285ae276173598c","8649d0e7a35e4cb684931179ebe6b5a4","11dc6019491547368e0ec5d969621b4e"]},"execution":{"iopub.execute_input":"2023-06-10T14:47:50.361301Z","iopub.status.busy":"2023-06-10T14:47:50.360813Z","iopub.status.idle":"2023-06-10T14:47:51.034292Z","shell.execute_reply":"2023-06-10T14:47:51.033211Z","shell.execute_reply.started":"2023-06-10T14:47:50.361260Z"},"executionInfo":{"elapsed":29318,"status":"ok","timestamp":1686325023810,"user":{"displayName":"Angelo Galavotti (turtleturd)","userId":"13066918554475446773"},"user_tz":-120},"id":"AoeyVDv9uDwx","outputId":"48731dfc-b5c3-46d1-c2c9-4e28cb2b288d","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"358753e809ec4c51a65e31ccac7f2b6e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"wikipedia\", \"20220301.simple\")\n","\n","data = dataset['train'][:20000]['text']"]},{"cell_type":"markdown","metadata":{"id":"U1AMjEbEaGu4"},"source":["# Tokenization"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-06-10T14:47:51.036939Z","iopub.status.busy":"2023-06-10T14:47:51.036597Z","iopub.status.idle":"2023-06-10T14:48:18.022824Z","shell.execute_reply":"2023-06-10T14:48:18.021724Z","shell.execute_reply.started":"2023-06-10T14:47:51.036908Z"},"executionInfo":{"elapsed":18869,"status":"ok","timestamp":1686325042641,"user":{"displayName":"Angelo Galavotti (turtleturd)","userId":"13066918554475446773"},"user_tz":-120},"id":"OzcYlWm8trh9","outputId":"2dd43995-9e03-4301-f8d0-0cdff61b3293","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["corpus dim:  510023\n","filtered sentences:  137301\n"]}],"source":["#run this cell only the first time to create and save the tokenizer and the date\n","dump = True\n","\n","tokenizer = Tokenizer(split=' ', filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n', num_words=10000, oov_token='<unk>')\n","\n","corpus = []\n","\n","# Split of each piece of text into sentences\n","for elem in data:\n","  corpus += elem.lower().replace(\"\\n\", \"\").split(\".\")[:]\n","\n","print(\"corpus dim: \",len(corpus))\n","\n","#add a start and an end token\n","corpus = ['<start> '+s+' <end>' for s in corpus]\n","\n","\n","# Tokenization\t\n","tokenizer.fit_on_texts(corpus)\n","#print(tokenizer.word_index['<unk>'])\n","\n","if dump:\n","    with open('tokenizer.pickle', 'wb') as handle:\n","        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","original_data = [sen for sen in tokenizer.texts_to_sequences(corpus) if (len(sen) <= 32 and len(sen)>4 and not(1 in sen))]\n","\n","if dump:\n","    with open('original.pickle', 'wb') as handle:\n","        pickle.dump(original_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","print (\"filtered sentences: \",len(original_data))\n","\n","sos = tokenizer.word_index['<start>']\n","eos = tokenizer.word_index['<end>']\n","#print(eos)\n","#print(tokenizer.index_word[sos])\n","\n","tokenizer.word_index['<pad>'] = 0\n","tokenizer.index_word[0] = '<pad>'\n","\n","# dimension of the vocabulary of tokens\n","vocab_dimension = len(tokenizer.word_index) + 1"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T14:48:18.026418Z","iopub.status.busy":"2023-06-10T14:48:18.025447Z","iopub.status.idle":"2023-06-10T14:48:20.820703Z","shell.execute_reply":"2023-06-10T14:48:20.819733Z","shell.execute_reply.started":"2023-06-10T14:48:18.026376Z"},"id":"rs4cerfa4D15","trusted":true},"outputs":[],"source":["shuffled_data = [random.sample(s[1:-1],len(s)-2) for s in original_data]\n","shuffled_data = [[sos]+s+[eos] for s in shuffled_data] # shuffled_data is an input of the model\n","target_data = [s[1:] for s in original_data] # target_data is the same as original data but offset by one timestep"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T14:48:20.823140Z","iopub.status.busy":"2023-06-10T14:48:20.822120Z","iopub.status.idle":"2023-06-10T14:48:20.949464Z","shell.execute_reply":"2023-06-10T14:48:20.948551Z","shell.execute_reply.started":"2023-06-10T14:48:20.823103Z"},"id":"dIDuV_Sj9oZo","trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, c_train, c_test, y_train, y_test = train_test_split(original_data, shuffled_data, target_data, test_size = 0.3, random_state = 42)\n"]},{"cell_type":"markdown","metadata":{"id":"kuV0iBS1aLa1"},"source":["## Score function\n","\n"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T14:48:20.951434Z","iopub.status.busy":"2023-06-10T14:48:20.951046Z","iopub.status.idle":"2023-06-10T14:48:20.958300Z","shell.execute_reply":"2023-06-10T14:48:20.957236Z","shell.execute_reply.started":"2023-06-10T14:48:20.951401Z"},"id":"ulpTRdrF_huh","trusted":true},"outputs":[],"source":["from difflib import SequenceMatcher\n","\n","def score(s,p):\n","  match = SequenceMatcher(None, s, p).find_longest_match()\n","  #print(match.size)\n","  return (match.size/max(len(s),len(p)))\n","\n","def clean_sentence(x):\n","  x = x.replace('<start>', '').replace('<end>', '').replace('<pad>', '').strip()\n","  return x"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T14:48:20.960118Z","iopub.status.busy":"2023-06-10T14:48:20.959788Z","iopub.status.idle":"2023-06-10T14:48:20.971412Z","shell.execute_reply":"2023-06-10T14:48:20.970386Z","shell.execute_reply.started":"2023-06-10T14:48:20.960085Z"},"id":"FFZbIgr9UWm7","trusted":true},"outputs":[],"source":["from difflib import SequenceMatcher\n","\n","def score(s,p):\n","  match = SequenceMatcher(None, s, p).find_longest_match()\n","  #print(match.size)\n","  return (match.size/max(len(s),len(p)))\n","\n","def clean_sentence(x):\n","  x = x.replace('<start>', '').replace('<end>', '').replace('<pad>', '').strip()\n","  return x"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-06-10T14:48:20.976816Z","iopub.status.busy":"2023-06-10T14:48:20.976487Z","iopub.status.idle":"2023-06-10T14:48:20.982926Z","shell.execute_reply":"2023-06-10T14:48:20.981979Z","shell.execute_reply.started":"2023-06-10T14:48:20.976790Z"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1686325045475,"user":{"displayName":"Angelo Galavotti (turtleturd)","userId":"13066918554475446773"},"user_tz":-120},"id":"OHWADl8js7AD","outputId":"c2177102-7dc8-4fa4-e8d5-f570ccd5a991","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["original sentence:  [2, 4, 780, 14, 5, 60, 829, 6, 1043, 20, 188, 1520, 21, 191, 31, 9, 75, 172, 1520, 18, 56, 23, 2053, 1777, 3]\n","shuffled sentecen:  [2, 9, 60, 31, 18, 23, 2053, 191, 780, 172, 188, 14, 75, 56, 6, 1777, 20, 1520, 1520, 21, 4, 5, 829, 1043, 3]\n"]}],"source":["i = np.random.randint(len(original_data))\n","print(\"original sentence: \",original_data[i])\n","print(\"shuffled sentecen: \",shuffled_data[i])"]},{"cell_type":"markdown","metadata":{"id":"qrLDU4CEaUnl"},"source":["## Dataset padding/formatting"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-06-10T14:48:20.984910Z","iopub.status.busy":"2023-06-10T14:48:20.984349Z","iopub.status.idle":"2023-06-10T14:48:23.056844Z","shell.execute_reply":"2023-06-10T14:48:23.055395Z","shell.execute_reply.started":"2023-06-10T14:48:20.984880Z"},"executionInfo":{"elapsed":1571,"status":"ok","timestamp":1686325047037,"user":{"displayName":"Angelo Galavotti (turtleturd)","userId":"13066918554475446773"},"user_tz":-120},"id":"cbZ1tSFN-kWj","outputId":"5ac9c4b2-0cc3-4cf0-a3a5-4530463d27e3","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["x_train size: 96110\n","96110\n","96110\n","96110\n"]}],"source":["max_sequence_len = max([len(x) for x in original_data])\n","\n","x_train = pad_sequences(x_train, maxlen=max_sequence_len, padding='post')\n","x_test = pad_sequences(x_test, maxlen=max_sequence_len, padding='post')\n","c_train = pad_sequences(c_train, maxlen=max_sequence_len, padding='post')\n","c_test = pad_sequences(c_test, maxlen=max_sequence_len, padding='post')\n","y_train = pad_sequences(y_train, maxlen=max_sequence_len, padding='post')\n","y_test = pad_sequences(y_test, maxlen=max_sequence_len, padding='post')\n","\n","print(\"x_train size:\", len(x_train))\n","assert(len(x_train)==len(c_train)==len(y_train))\n","print(len(x_train))\n","print(len(c_train))\n","print(len(y_train))"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-06-10T14:48:23.058717Z","iopub.status.busy":"2023-06-10T14:48:23.058384Z","iopub.status.idle":"2023-06-10T14:48:23.065107Z","shell.execute_reply":"2023-06-10T14:48:23.064120Z","shell.execute_reply.started":"2023-06-10T14:48:23.058685Z"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1686325047039,"user":{"displayName":"Angelo Galavotti (turtleturd)","userId":"13066918554475446773"},"user_tz":-120},"id":"dRSfeqwat6t2","outputId":"8acc3c95-b396-4957-83e7-8db27bb6f303","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["original sentence:  <start> in this way people can read many articles easily but it is illegal <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n","shuffled sentence:  <start> many way people articles it read in easily but illegal this is can <end> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"]}],"source":["i = np.random.randint(len(x_train))\n","print(\"original sentence: \",tokenizer.sequences_to_texts([x_train[i]])[0])\n","print(\"shuffled sentence: \",tokenizer.sequences_to_texts([c_train[i]])[0])"]},{"cell_type":"markdown","metadata":{"id":"oyFvHGG9IE89"},"source":["# The model\n","After some attempts using RNNs and LSTMs, I decided to opt for a different model. This is due to many reasons, mainly:\n","\n","- They capture hidden dependendencies in data. \n","\n","- They make no assumptions about the __spatial__ relationships across data. \n","\n","The latter concept was essential for the performance of this model. In fact, the model should behave the same regardless of the ordering of the inputs: a property that is not ensured by LSTMs.   \n"]},{"cell_type":"markdown","metadata":{"id":"KzqoQPgYSlLS"},"source":["## Building the layers\n","\n","The model is comprised of this type of layers:\n","- Base attention layer\n","- Cross attention layer \n","- Global and Causal self attention layer\n","- Feed Forward layer\n","\n","Let's look over their code and their inner functioning."]},{"cell_type":"markdown","metadata":{"id":"zJRb9ZCGjLdk"},"source":["### Base Attention Layer\n","\n","The Base attention layer is comprised of a Multi-Nead attention layer, with a Add & Norm layer. \n","\n","In particular, each attention head can specialize in different aspects or dependendecies of the sequence it receives. \n"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T15:05:16.589583Z","iopub.status.busy":"2023-06-10T15:05:16.588882Z","iopub.status.idle":"2023-06-10T15:05:16.595698Z","shell.execute_reply":"2023-06-10T15:05:16.594757Z","shell.execute_reply.started":"2023-06-10T15:05:16.589547Z"},"id":"CS7FrqVlUW6r","trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from keras.layers import Embedding\n","\n","class BaseAttention(tf.keras.layers.Layer):\n","  def __init__(self, **kwargs):\n","    super().__init__()\n","    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n","    self.layernorm = tf.keras.layers.LayerNormalization()\n","    self.add = tf.keras.layers.Add()"]},{"cell_type":"markdown","metadata":{"id":"XzpboBS4klbO"},"source":["### Cross-attention layer\n","The cross-attention layer connects the encoder and the decoder of the model by means of a context vector. "]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T14:48:23.078052Z","iopub.status.busy":"2023-06-10T14:48:23.077677Z","iopub.status.idle":"2023-06-10T14:48:23.086328Z","shell.execute_reply":"2023-06-10T14:48:23.085523Z","shell.execute_reply.started":"2023-06-10T14:48:23.078023Z"},"id":"ey9sLA3yGM2n","trusted":true},"outputs":[],"source":["class CrossAttention(BaseAttention):\n","  def call(self, x, context):\n","    attn_output, attn_scores = self.mha(\n","        query=x,\n","        key=context,\n","        value=context,\n","        return_attention_scores=True)\n","\n","    # Cache the attention scores\n","    self.last_attn_scores = attn_scores\n","\n","    x = self.add([x, attn_output])\n","    x = self.layernorm(x)\n","\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"nZU30IQPl85e"},"source":["### Global self attention layer\n","This layer is responsible for processing/generating the context sequence, and propagating information along its length."]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T14:48:23.088391Z","iopub.status.busy":"2023-06-10T14:48:23.087447Z","iopub.status.idle":"2023-06-10T14:48:23.099412Z","shell.execute_reply":"2023-06-10T14:48:23.098498Z","shell.execute_reply.started":"2023-06-10T14:48:23.088361Z"},"id":"0e7TDSPNGVVE","trusted":true},"outputs":[],"source":["class GlobalSelfAttention(BaseAttention):\n","  def call(self, x):\n","    attn_output = self.mha(\n","        query=x,\n","        value=x,\n","        key=x)\n","    x = self.add([x, attn_output])\n","    x = self.layernorm(x)\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"q_olhNUKxoAH"},"source":["### Causal self attention layer\n","This layer does the same thing as the Global Attetion layer but for the output sequence.\n","\n","As a matter of fact, their structure is very similar.  "]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T14:48:23.101019Z","iopub.status.busy":"2023-06-10T14:48:23.100574Z","iopub.status.idle":"2023-06-10T14:48:23.109452Z","shell.execute_reply":"2023-06-10T14:48:23.108516Z","shell.execute_reply.started":"2023-06-10T14:48:23.100987Z"},"id":"3Ls080NgHUz1","trusted":true},"outputs":[],"source":["class CausalSelfAttention(BaseAttention):\n","  def call(self, x):\n","    attn_output = self.mha(\n","        query=x,\n","        value=x,\n","        key=x,\n","        use_causal_mask = True)\n","    x = self.add([x, attn_output])\n","    x = self.layernorm(x)\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"yXiiyNdQyiTO"},"source":["### Feed forward layer\n","\n","This layer is comprised of two dense layers with relu activation, as well as a dropout layer, which helps in reducing overfitting."]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T14:48:23.111213Z","iopub.status.busy":"2023-06-10T14:48:23.110649Z","iopub.status.idle":"2023-06-10T14:48:23.120109Z","shell.execute_reply":"2023-06-10T14:48:23.119185Z","shell.execute_reply.started":"2023-06-10T14:48:23.111141Z"},"id":"RW3oSTI-HZJB","trusted":true},"outputs":[],"source":["class FeedForward(tf.keras.layers.Layer):\n","  def __init__(self, d_model, dff, dropout_rate=0.1):\n","    super().__init__()\n","    self.seq = tf.keras.Sequential([\n","      tf.keras.layers.Dense(dff, activation='relu'),\n","      tf.keras.layers.Dense(d_model),\n","      tf.keras.layers.Dropout(dropout_rate)\n","    ])\n","    self.add = tf.keras.layers.Add()\n","    self.layer_norm = tf.keras.layers.LayerNormalization()\n","\n","  def call(self, x):\n","    x = self.add([x, self.seq(x)])\n","    x = self.layer_norm(x) \n","    return x"]},{"cell_type":"markdown","metadata":{"id":"90lMUG0rhPoY"},"source":["### Positional Embedding Layer\n","\n","A normal embedding layer converts the input into a vector, in order to be given as input to a neural network. \n","\n","A positional embedding makes use of a positional encoding in order to give importance to the position of a word in a sequence."]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T14:48:23.122109Z","iopub.status.busy":"2023-06-10T14:48:23.121685Z","iopub.status.idle":"2023-06-10T14:48:23.130684Z","shell.execute_reply":"2023-06-10T14:48:23.130045Z","shell.execute_reply.started":"2023-06-10T14:48:23.122079Z"},"id":"D4-r60R_mNFi","trusted":true},"outputs":[],"source":["def positional_encoding(length, depth):\n","  depth = depth/2\n","\n","  positions = np.arange(length)[:, np.newaxis]    \n","  depths = np.arange(depth)[np.newaxis, :]/depth   \n","\n","  angle_rates = 1 / (10000**depths)         \n","  angle_rads = positions * angle_rates      \n","\n","  pos_encoding = np.concatenate(\n","      [np.sin(angle_rads), np.cos(angle_rads)],\n","      axis=-1) \n","\n","  return tf.cast(pos_encoding, dtype=tf.float32)"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T14:48:23.132598Z","iopub.status.busy":"2023-06-10T14:48:23.131802Z","iopub.status.idle":"2023-06-10T14:48:23.140713Z","shell.execute_reply":"2023-06-10T14:48:23.140045Z","shell.execute_reply.started":"2023-06-10T14:48:23.132567Z"},"id":"kL60NB34IKre","trusted":true},"outputs":[],"source":["def PositionalEmbedding(length, depth):\n","  depth = depth/2\n","\n","  positions = np.arange(length)[:, np.newaxis]     \n","  depths = np.arange(depth)[np.newaxis, :]/depth   \n","\n","  angle_rates = 1 / (10000**depths)        \n","  angle_rads = positions * angle_rates    \n","\n","  pos_encoding = np.concatenate(\n","      [np.sin(angle_rads), np.cos(angle_rads)],\n","      axis=-1) \n","\n","  return tf.cast(pos_encoding, dtype=tf.float32)"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T14:48:23.142743Z","iopub.status.busy":"2023-06-10T14:48:23.141826Z","iopub.status.idle":"2023-06-10T14:48:23.155104Z","shell.execute_reply":"2023-06-10T14:48:23.154213Z","shell.execute_reply.started":"2023-06-10T14:48:23.142713Z"},"id":"GOEQMlnULzPT","trusted":true},"outputs":[],"source":["class PositionalEmbedding(tf.keras.layers.Layer):\n","  def __init__(self, vocab_size, d_model):\n","    super().__init__()\n","    self.d_model = d_model\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True) \n","    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n","\n","  def compute_mask(self, *args, **kwargs):\n","    return self.embedding.compute_mask(*args, **kwargs)\n","\n","  def call(self, x):\n","    length = tf.shape(x)[1]\n","    x = self.embedding(x)\n","    # This factor sets the relative scale of the embedding and positonal_encoding.\n","    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","    x = x + self.pos_encoding[tf.newaxis, :length, :]\n","    return x\n"]},{"cell_type":"markdown","metadata":{"id":"oUDsokzfHh1_"},"source":["# Encoder\n","\n","The encoder takes as input the shuffled sentence, and computes the context vector which is given to the decorder through the cross-attention layer. \n","\n","It is made of a stack of encoder layers.\n","\n","## Encoder Layer\n","Each encoding layer is made of a Global self attention layer and a feed forward layer. "]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T14:48:23.156818Z","iopub.status.busy":"2023-06-10T14:48:23.156349Z","iopub.status.idle":"2023-06-10T14:48:23.165814Z","shell.execute_reply":"2023-06-10T14:48:23.164581Z","shell.execute_reply.started":"2023-06-10T14:48:23.156783Z"},"id":"nTvZYRHBHk9d","trusted":true},"outputs":[],"source":["class EncoderLayer(tf.keras.layers.Layer):\n","  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n","    super().__init__()\n","\n","    self.self_attention = GlobalSelfAttention(\n","        num_heads=num_heads,\n","        key_dim=d_model,\n","        dropout=dropout_rate)\n","\n","    self.ffn = FeedForward(d_model, dff)\n","\n","  def call(self, x):\n","    x = self.self_attention(x)\n","    x = self.ffn(x)\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"aQxBAia2H3W2"},"source":["In the encoder, the positional embedding layer is removed, and is swapped with a normal embedding layer. \n","\n","This isn't without any reason: without the positional embedding, our input is seen as a \"bag of words\", in which the order of each word is not taken into account. \n","\n","This is exactly what we want: in fact, the model should behave in the same way with each possible sequence of the same set of words.  "]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T14:48:23.167352Z","iopub.status.busy":"2023-06-10T14:48:23.166967Z","iopub.status.idle":"2023-06-10T14:48:23.176717Z","shell.execute_reply":"2023-06-10T14:48:23.176058Z","shell.execute_reply.started":"2023-06-10T14:48:23.167321Z"},"id":"MwndeMKHH3z-","trusted":true},"outputs":[],"source":["class Encoder(tf.keras.layers.Layer):\n","  def __init__(self, *, num_layers, d_model, num_heads,\n","               dff, vocab_size, dropout_rate=0.1):\n","    super().__init__()\n","\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","\n","    # No positional embedding, since we need this model to treat input as BoW\n","    self.embedding = Embedding(input_dim=vocab_size, output_dim=d_model) \n","\n","    self.enc_layers = [\n","        EncoderLayer(d_model=d_model,\n","                     num_heads=num_heads,\n","                     dff=dff,\n","                     dropout_rate=dropout_rate)\n","        for _ in range(num_layers)]\n","    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n","\n","  def call(self, x):\n","    x = self.embedding(x)  \n","\n","    x = self.dropout(x)\n","\n","    for i in range(self.num_layers):\n","      x = self.enc_layers[i](x)\n","\n","    return x "]},{"cell_type":"markdown","metadata":{"id":"pTcFmd0EIHNg"},"source":["## Decoder\n","The structure of the decoder is very similar to the structure of the encoder, aside from a few differences. \n","\n","### Decoder layer\n","Each encoding layer is made of a Causal self attention layer and a feed forward layer.\n","\n","In addition, it incorporates the cross attention layer, to receive the context vector."]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T14:48:23.178861Z","iopub.status.busy":"2023-06-10T14:48:23.178243Z","iopub.status.idle":"2023-06-10T14:48:23.188974Z","shell.execute_reply":"2023-06-10T14:48:23.188325Z","shell.execute_reply.started":"2023-06-10T14:48:23.178830Z"},"id":"FwF30E43IGMO","trusted":true},"outputs":[],"source":["class DecoderLayer(tf.keras.layers.Layer):\n","  def __init__(self,\n","               *,\n","               d_model,\n","               num_heads,\n","               dff,\n","               dropout_rate=0.1):\n","    super(DecoderLayer, self).__init__()\n","\n","    self.causal_self_attention = CausalSelfAttention(\n","        num_heads=num_heads,\n","        key_dim=d_model,\n","        dropout=dropout_rate)\n","\n","    self.cross_attention = CrossAttention(\n","        num_heads=num_heads,\n","        key_dim=d_model,\n","        dropout=dropout_rate)\n","\n","    self.ffn = FeedForward(d_model, dff)\n","\n","  def call(self, x, context):\n","    x = self.causal_self_attention(x=x)\n","    x = self.cross_attention(x=x, context=context)\n","\n","    # Cache the last attention scores\n","    self.last_attn_scores = self.cross_attention.last_attn_scores\n","\n","    x = self.ffn(x)  \n","    return x"]},{"cell_type":"markdown","metadata":{"id":"1AG5Z_5HIQbQ"},"source":["As opposed to the encoder, in the decoder we have a positional embedding, since, during teacher forcing, it must capture the underlying positional information embedded in the sentence. "]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T14:48:23.190894Z","iopub.status.busy":"2023-06-10T14:48:23.190188Z","iopub.status.idle":"2023-06-10T14:48:23.200237Z","shell.execute_reply":"2023-06-10T14:48:23.199635Z","shell.execute_reply.started":"2023-06-10T14:48:23.190862Z"},"id":"KcPe-ffwISfO","trusted":true},"outputs":[],"source":["class Decoder(tf.keras.layers.Layer):\n","  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n","               dropout_rate=0.1):\n","    super(Decoder, self).__init__()\n","\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","\n","    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n","                                             d_model=d_model)\n","    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n","    self.dec_layers = [\n","        DecoderLayer(d_model=d_model, num_heads=num_heads,\n","                     dff=dff, dropout_rate=dropout_rate)\n","        for _ in range(num_layers)]\n","\n","    self.last_attn_scores = None\n","\n","  def call(self, x, context):\n","    x = self.pos_embedding(x)  \n","\n","    x = self.dropout(x)\n","\n","    for i in range(self.num_layers):\n","      x  = self.dec_layers[i](x, context)\n","\n","    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n","\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"JN4cxVFEIXeY"},"source":["# Final transformer\n","\n","Putting everything together, we obtain the transformer. \n","\n","We are also adding an additonal final Dense layer, which converts the resulting vector at each location into output token probabilities."]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T14:48:23.202287Z","iopub.status.busy":"2023-06-10T14:48:23.201644Z","iopub.status.idle":"2023-06-10T14:48:23.212872Z","shell.execute_reply":"2023-06-10T14:48:23.212228Z","shell.execute_reply.started":"2023-06-10T14:48:23.202256Z"},"id":"gk2JGKSdIWtz","trusted":true},"outputs":[],"source":["class Transformer(tf.keras.Model):\n","  def __init__(self, *, num_layers, d_model, num_heads, dff,\n","               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n","    super().__init__()\n","    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n","                           num_heads=num_heads, dff=dff,\n","                           vocab_size=input_vocab_size,\n","                           dropout_rate=dropout_rate)\n","\n","    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n","                           num_heads=num_heads, dff=dff,\n","                           vocab_size=target_vocab_size,\n","                           dropout_rate=dropout_rate)\n","\n","    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n","\n","  def call(self, inputs):\n","    # computing and giving context to decoder\n","    context, x  = inputs\n","    context = self.encoder(context)\n","    x = self.decoder(x, context)\n","\n","    # Final linear layer output.\n","    logits = self.final_layer(x) \n","\n","    try:\n","      # Drop the keras mask, so it doesn't scale the losses/metrics.\n","      del logits._keras_mask\n","    except AttributeError:\n","      pass\n","\n","    return logits"]},{"cell_type":"markdown","metadata":{"id":"TXfcKM18I9B0"},"source":["### Instatiating the model\n","\n","The model is instantiated with the following parameters.\n","\n","Each of them was chosen through trial and error, by training different models with different combinations of parameters. \n","\n","Some of the most influential were the number of heads and the dropout rate.\n","- The number of heads influences how the model captures the underlying dependencies in sequences. \n","- The droupout rate influences how much the model is subject to overfitting and underfitting.  "]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T14:50:05.457985Z","iopub.status.busy":"2023-06-10T14:50:05.457016Z","iopub.status.idle":"2023-06-10T14:50:05.593947Z","shell.execute_reply":"2023-06-10T14:50:05.593007Z","shell.execute_reply.started":"2023-06-10T14:50:05.457949Z"},"id":"vJnBfi91I9af","trusted":true},"outputs":[],"source":["num_layers = 4\n","d_model = 128\n","dff = 512\n","num_heads = 8\n","dropout_rate = 0.2\n","\n","transformer = Transformer(\n","    num_layers=num_layers,\n","    d_model=d_model,\n","    num_heads=num_heads,\n","    dff=dff,\n","    input_vocab_size=10_000,\n","    target_vocab_size=10_000,\n","    dropout_rate=dropout_rate)"]},{"cell_type":"markdown","metadata":{"id":"8qNSIhl1Ig5w"},"source":["# Training the model\n","\n","---\n","\n","The model uses an Adam optimizer. The learning rate schedule was chosen according to the paper \"Attention is all you need\" in which Transformers where first introduced. "]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T14:50:14.562716Z","iopub.status.busy":"2023-06-10T14:50:14.562035Z","iopub.status.idle":"2023-06-10T14:50:14.569456Z","shell.execute_reply":"2023-06-10T14:50:14.568497Z","shell.execute_reply.started":"2023-06-10T14:50:14.562680Z"},"id":"8dqYAzEvIgAG","trusted":true},"outputs":[],"source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","  def __init__(self, d_model, warmup_steps=4000):\n","    super().__init__()\n","\n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","    self.warmup_steps = warmup_steps\n","\n","  def __call__(self, step):\n","    step = tf.cast(step, dtype=tf.float32)\n","    arg1 = tf.math.rsqrt(step)\n","    arg2 = step * (self.warmup_steps ** -1.5)\n","\n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T14:50:22.769768Z","iopub.status.busy":"2023-06-10T14:50:22.769413Z","iopub.status.idle":"2023-06-10T14:50:22.778133Z","shell.execute_reply":"2023-06-10T14:50:22.777121Z","shell.execute_reply.started":"2023-06-10T14:50:22.769740Z"},"id":"8mOlfQBmJRe2","trusted":true},"outputs":[],"source":["learning_rate = CustomSchedule(d_model)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n","                                     epsilon=1e-9)"]},{"cell_type":"markdown","metadata":{"id":"r6aG5UFI7vjZ"},"source":["### Loss function and metrics\n","The sparse categorical cross-entropy and accuracy are extended to include a padding mask.\n"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T14:50:25.334112Z","iopub.status.busy":"2023-06-10T14:50:25.333752Z","iopub.status.idle":"2023-06-10T14:50:25.341619Z","shell.execute_reply":"2023-06-10T14:50:25.340707Z","shell.execute_reply.started":"2023-06-10T14:50:25.334083Z"},"id":"NxCoIGaSJdgf","trusted":true},"outputs":[],"source":["def masked_loss(label, pred):\n","  mask = label != 0\n","  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n","  loss = loss_object(label, pred)\n","\n","  mask = tf.cast(mask, dtype=loss.dtype)\n","  loss *= mask\n","\n","  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n","  return loss\n","\n","\n","def masked_accuracy(label, pred):\n","  pred = tf.argmax(pred, axis=2)\n","  label = tf.cast(label, pred.dtype)\n","  match = label == pred\n","\n","  mask = label != 0\n","\n","  match = match & mask\n","\n","  match = tf.cast(match, dtype=tf.float32)\n","  mask = tf.cast(mask, dtype=tf.float32)\n","  return tf.reduce_sum(match)/tf.reduce_sum(mask)"]},{"cell_type":"markdown","metadata":{"id":"bCNcPA1P8CIc"},"source":["### Compiling and training the model\n","\n","The model is built and set up for training. "]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T15:03:06.435118Z","iopub.status.busy":"2023-06-10T15:03:06.434716Z","iopub.status.idle":"2023-06-10T15:03:06.448640Z","shell.execute_reply":"2023-06-10T15:03:06.447707Z","shell.execute_reply.started":"2023-06-10T15:03:06.435089Z"},"id":"hJyCeP1-JieO","trusted":true},"outputs":[],"source":["transformer.compile(\n","    loss=masked_loss,\n","    optimizer=optimizer,\n","    metrics=[masked_accuracy]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5680516,"status":"ok","timestamp":1686336153273,"user":{"displayName":"Angelo Galavotti (turtleturd)","userId":"13066918554475446773"},"user_tz":-120},"id":"0pw0JlwrJktJ","outputId":"69068b29-969f-430a-c923-fb4eeb99c869"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","\n","357/357 [==============================] - 186s 416ms/step - loss: 8.2259 - masked_accuracy: 0.1062 - val_loss: 6.9074 - val_masked_accuracy: 0.1428\n","\n","Epoch 2/50\n","\n","357/357 [==============================] - 117s 328ms/step - loss: 6.1884 - masked_accuracy: 0.1925 - val_loss: 5.4053 - val_masked_accuracy: 0.2822\n","\n","Epoch 3/50\n","\n","357/357 [==============================] - 115s 321ms/step - loss: 4.9012 - masked_accuracy: 0.3262 - val_loss: 4.2626 - val_masked_accuracy: 0.3935\n","\n","Epoch 4/50\n","\n","357/357 [==============================] - 114s 320ms/step - loss: 3.9539 - masked_accuracy: 0.4154 - val_loss: 3.4291 - val_masked_accuracy: 0.4757\n","\n","Epoch 5/50\n","\n","357/357 [==============================] - 113s 315ms/step - loss: 3.1970 - masked_accuracy: 0.4888 - val_loss: 2.7783 - val_masked_accuracy: 0.5496\n","\n","Epoch 6/50\n","\n","357/357 [==============================] - 113s 316ms/step - loss: 2.5962 - masked_accuracy: 0.5464 - val_loss: 2.2657 - val_masked_accuracy: 0.5936\n","\n","Epoch 7/50\n","\n","357/357 [==============================] - 112s 313ms/step - loss: 2.1597 - masked_accuracy: 0.5874 - val_loss: 1.9209 - val_masked_accuracy: 0.6282\n","\n","Epoch 8/50\n","\n","357/357 [==============================] - 112s 313ms/step - loss: 1.8573 - masked_accuracy: 0.6175 - val_loss: 1.7337 - val_masked_accuracy: 0.6507\n","\n","Epoch 9/50\n","\n","357/357 [==============================] - 112s 313ms/step - loss: 1.6527 - masked_accuracy: 0.6399 - val_loss: 1.6048 - val_masked_accuracy: 0.6655\n","\n","Epoch 10/50\n","\n","357/357 [==============================] - 112s 314ms/step - loss: 1.5165 - masked_accuracy: 0.6564 - val_loss: 1.5380 - val_masked_accuracy: 0.6743\n","\n","Epoch 11/50\n","\n","357/357 [==============================] - 112s 313ms/step - loss: 1.4235 - masked_accuracy: 0.6691 - val_loss: 1.4807 - val_masked_accuracy: 0.6798\n","\n","Epoch 12/50\n","\n","357/357 [==============================] - 112s 315ms/step - loss: 1.3379 - masked_accuracy: 0.6815 - val_loss: 1.4253 - val_masked_accuracy: 0.6912\n","\n","Epoch 13/50\n","\n","357/357 [==============================] - 112s 314ms/step - loss: 1.2310 - masked_accuracy: 0.6982 - val_loss: 1.3956 - val_masked_accuracy: 0.6989\n","\n","Epoch 14/50\n","\n","357/357 [==============================] - 112s 314ms/step - loss: 1.1418 - masked_accuracy: 0.7134 - val_loss: 1.3350 - val_masked_accuracy: 0.7048\n","\n","Epoch 15/50\n","\n","357/357 [==============================] - 112s 314ms/step - loss: 1.0642 - masked_accuracy: 0.7262 - val_loss: 1.2882 - val_masked_accuracy: 0.7184\n","\n","Epoch 16/50\n","\n","357/357 [==============================] - 112s 315ms/step - loss: 0.9991 - masked_accuracy: 0.7383 - val_loss: 1.2809 - val_masked_accuracy: 0.7175\n","\n","Epoch 17/50\n","\n","357/357 [==============================] - 112s 313ms/step - loss: 0.9416 - masked_accuracy: 0.7494 - val_loss: 1.2556 - val_masked_accuracy: 0.7252\n","\n","Epoch 18/50\n","\n","357/357 [==============================] - 112s 314ms/step - loss: 0.8897 - masked_accuracy: 0.7596 - val_loss: 1.2491 - val_masked_accuracy: 0.7253\n","\n","Epoch 19/50\n","\n","357/357 [==============================] - 111s 312ms/step - loss: 0.8467 - masked_accuracy: 0.7682 - val_loss: 1.2536 - val_masked_accuracy: 0.7272\n","\n","Epoch 20/50\n","\n","357/357 [==============================] - 112s 313ms/step - loss: 0.8083 - masked_accuracy: 0.7764 - val_loss: 1.2510 - val_masked_accuracy: 0.7281\n","\n","Epoch 21/50\n","\n","357/357 [==============================] - 112s 313ms/step - loss: 0.7719 - masked_accuracy: 0.7842 - val_loss: 1.2376 - val_masked_accuracy: 0.7318\n","\n","Epoch 22/50\n","\n","357/357 [==============================] - 113s 316ms/step - loss: 0.7393 - masked_accuracy: 0.7908 - val_loss: 1.2476 - val_masked_accuracy: 0.7366\n","\n","Epoch 23/50\n","\n","357/357 [==============================] - 112s 313ms/step - loss: 0.7090 - masked_accuracy: 0.7974 - val_loss: 1.2371 - val_masked_accuracy: 0.7368\n","\n","Epoch 24/50\n","\n","357/357 [==============================] - 112s 313ms/step - loss: 0.6834 - masked_accuracy: 0.8034 - val_loss: 1.2363 - val_masked_accuracy: 0.7394\n","\n","Epoch 25/50\n","\n","357/357 [==============================] - 111s 312ms/step - loss: 0.6574 - masked_accuracy: 0.8096 - val_loss: 1.2489 - val_masked_accuracy: 0.7362\n","\n","Epoch 26/50\n","\n","357/357 [==============================] - 112s 313ms/step - loss: 0.6345 - masked_accuracy: 0.8148 - val_loss: 1.2341 - val_masked_accuracy: 0.7429\n","\n","Epoch 27/50\n","\n","357/357 [==============================] - 112s 313ms/step - loss: 0.6137 - masked_accuracy: 0.8202 - val_loss: 1.2481 - val_masked_accuracy: 0.7405\n","\n","Epoch 28/50\n","\n","357/357 [==============================] - 112s 313ms/step - loss: 0.5922 - masked_accuracy: 0.8249 - val_loss: 1.2349 - val_masked_accuracy: 0.7438\n","\n","Epoch 29/50\n","\n","357/357 [==============================] - 112s 314ms/step - loss: 0.5745 - masked_accuracy: 0.8295 - val_loss: 1.2563 - val_masked_accuracy: 0.7436\n","\n","Epoch 30/50\n","\n","357/357 [==============================] - 112s 314ms/step - loss: 0.5568 - masked_accuracy: 0.8340 - val_loss: 1.2562 - val_masked_accuracy: 0.7413\n","\n","Epoch 31/50\n","\n","357/357 [==============================] - 112s 314ms/step - loss: 0.5404 - masked_accuracy: 0.8378 - val_loss: 1.2522 - val_masked_accuracy: 0.7441\n","\n","Epoch 32/50\n","\n","357/357 [==============================] - 112s 314ms/step - loss: 0.5238 - masked_accuracy: 0.8423 - val_loss: 1.2784 - val_masked_accuracy: 0.7446\n","\n","Epoch 33/50\n","\n","357/357 [==============================] - 113s 315ms/step - loss: 0.5096 - masked_accuracy: 0.8456 - val_loss: 1.2667 - val_masked_accuracy: 0.7470\n","\n","Epoch 34/50\n","\n","357/357 [==============================] - 112s 312ms/step - loss: 0.4976 - masked_accuracy: 0.8487 - val_loss: 1.2776 - val_masked_accuracy: 0.7446\n","\n","Epoch 35/50\n","\n","357/357 [==============================] - 111s 312ms/step - loss: 0.4852 - masked_accuracy: 0.8520 - val_loss: 1.2808 - val_masked_accuracy: 0.7465\n","\n","Epoch 36/50\n","\n","357/357 [==============================] - 112s 313ms/step - loss: 0.4711 - masked_accuracy: 0.8558 - val_loss: 1.2838 - val_masked_accuracy: 0.7484\n","\n","Epoch 37/50\n","\n","357/357 [==============================] - 111s 312ms/step - loss: 0.4605 - masked_accuracy: 0.8591 - val_loss: 1.2955 - val_masked_accuracy: 0.7491\n","\n","Epoch 38/50\n","\n","357/357 [==============================] - 111s 312ms/step - loss: 0.4482 - masked_accuracy: 0.8627 - val_loss: 1.3007 - val_masked_accuracy: 0.7466\n","\n","Epoch 39/50\n","\n","357/357 [==============================] - 112s 314ms/step - loss: 0.4377 - masked_accuracy: 0.8650 - val_loss: 1.3004 - val_masked_accuracy: 0.7492\n","\n","Epoch 40/50\n","\n","357/357 [==============================] - 112s 313ms/step - loss: 0.4298 - masked_accuracy: 0.8672 - val_loss: 1.3008 - val_masked_accuracy: 0.7489\n","\n","Epoch 41/50\n","\n","357/357 [==============================] - 112s 313ms/step - loss: 0.4200 - masked_accuracy: 0.8699 - val_loss: 1.3129 - val_masked_accuracy: 0.7518\n","\n","Epoch 42/50\n","\n","357/357 [==============================] - 111s 311ms/step - loss: 0.4119 - masked_accuracy: 0.8723 - val_loss: 1.3206 - val_masked_accuracy: 0.7511\n","\n","Epoch 43/50\n","\n","357/357 [==============================] - 112s 313ms/step - loss: 0.4014 - masked_accuracy: 0.8753 - val_loss: 1.3289 - val_masked_accuracy: 0.7501\n","\n","Epoch 44/50\n","\n","357/357 [==============================] - 112s 314ms/step - loss: 0.3938 - masked_accuracy: 0.8773 - val_loss: 1.3303 - val_masked_accuracy: 0.7502\n","\n","Epoch 45/50\n","\n","357/357 [==============================] - 112s 313ms/step - loss: 0.3850 - masked_accuracy: 0.8797 - val_loss: 1.3414 - val_masked_accuracy: 0.7502\n","\n","Epoch 46/50\n","\n","357/357 [==============================] - 112s 313ms/step - loss: 0.3779 - masked_accuracy: 0.8817 - val_loss: 1.3453 - val_masked_accuracy: 0.7521\n","\n","Epoch 47/50\n","\n","357/357 [==============================] - 111s 312ms/step - loss: 0.3707 - masked_accuracy: 0.8838 - val_loss: 1.3548 - val_masked_accuracy: 0.7523\n","\n","Epoch 48/50\n","\n","357/357 [==============================] - 112s 312ms/step - loss: 0.3625 - masked_accuracy: 0.8861 - val_loss: 1.3469 - val_masked_accuracy: 0.7495\n","\n","Epoch 49/50\n","\n","357/357 [==============================] - 111s 312ms/step - loss: 0.3562 - masked_accuracy: 0.8884 - val_loss: 1.3695 - val_masked_accuracy: 0.7518\n","\n","Epoch 50/50\n","\n","357/357 [==============================] - 112s 313ms/step - loss: 0.3505 - masked_accuracy: 0.8897 - val_loss: 1.3659 - val_masked_accuracy: 0.7499\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f122acaadd0>"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","\n","early_stopping = EarlyStopping(monitor='val_masked_accuracy', mode='max', verbose=1, patience=5)\n","\n","epochs = 50\n","batch_size = 256\n","\n","transformer.fit(\n","    (c_train, x_train),\n","    y_train,\n","    epochs=epochs,\n","    batch_size=batch_size,\n","    callbacks = [early_stopping],\n","    validation_split = 0.05\n",")"]},{"cell_type":"code","execution_count":80,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-06-10T15:13:45.071113Z","iopub.status.busy":"2023-06-10T15:13:45.070730Z","iopub.status.idle":"2023-06-10T15:13:45.115315Z","shell.execute_reply":"2023-06-10T15:13:45.114372Z","shell.execute_reply.started":"2023-06-10T15:13:45.071080Z"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1686336158346,"user":{"displayName":"Angelo Galavotti (turtleturd)","userId":"13066918554475446773"},"user_tz":-120},"id":"0iP3Bh2fZbZw","outputId":"73430d81-c821-4774-813b-cc8dfa3c7ddd","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"transformer_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," encoder_1 (Encoder)         multiple                  3918848   \n","                                                                 \n"," decoder (Decoder)           multiple                  6029824   \n","                                                                 \n"," dense_16 (Dense)            multiple                  1290000   \n","                                                                 \n","=================================================================\n","Total params: 11,238,672\n","Trainable params: 11,238,672\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["transformer.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"auH8QpQ5v051"},"outputs":[],"source":["### This code was used in order to load the saved model weights. It should be ignored. \n","\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# transformer.save_weights('drive/MyDrive/saved_model_weights_8_128_02/my_model_weights')"]},{"cell_type":"markdown","metadata":{"id":"mEqABVfOKKvz"},"source":["## Translator module\n","\n","This module is responsible for wrapping the computation of the transformer. \n","In essence, it generates a bag of words from a batch of shuffled sentences, and gradually computes the index of the best word prediction given by the transformer.  \n"]},{"cell_type":"code","execution_count":86,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T15:16:09.176872Z","iopub.status.busy":"2023-06-10T15:16:09.176120Z","iopub.status.idle":"2023-06-10T15:16:09.187049Z","shell.execute_reply":"2023-06-10T15:16:09.185971Z","shell.execute_reply.started":"2023-06-10T15:16:09.176837Z"},"id":"NUv_zDeUJqhL","trusted":true},"outputs":[],"source":["class Translator(tf.Module):\n","    def __init__(self, transformer, tokenizer):\n","        self.transformer = transformer\n","        self.tokenizer = tokenizer\n","              \n","    def __call__(self, sentences, max_length=max_sequence_len):\n","        batch_size = sentences.shape[0]\n","        \n","        # generate word list for each sentence\n","        bow = [[word for word in sentence if word not in [sos, eos, 0]] for sentence in sentences]\n","        # starting vector for prediction, it contains the sos index\n","        output = [[self.tokenizer.word_index['<start>']] for _ in range(batch_size)]\n","        # during inference, output will be filled with the final sentence. \n","\n","        for i in range(1, max_length):\n","            # (enc_input, dec_input)\n","            predictions = np.array(self.transformer((np.array(sentences), np.array(output))))\n","            \n","            # remove useless dimensions\n","            predictions = predictions[:, -1, :] \n","\n","            for j in range(batch_size):\n","                if len(bow[j]) == 0:\n","                    # no more words to use\n","                    cand_token = eos\n","                else:\n","                    # choose index with highest score\n","                    s_prediction = predictions[j, np.array(bow[j])]\n","                    cand_index = np.argmax(s_prediction)\n","                    cand_token = bow[j][cand_index]\n","                    del bow[j][cand_index]\n","                output[j].append(cand_token)\n","                \n","        return output"]},{"cell_type":"code","execution_count":87,"metadata":{"execution":{"iopub.execute_input":"2023-06-10T15:16:12.801955Z","iopub.status.busy":"2023-06-10T15:16:12.801582Z","iopub.status.idle":"2023-06-10T15:16:12.806876Z","shell.execute_reply":"2023-06-10T15:16:12.805960Z","shell.execute_reply.started":"2023-06-10T15:16:12.801927Z"},"id":"TyJdiHUBKSEh","trusted":true},"outputs":[],"source":["translator = Translator(transformer, tokenizer)"]},{"cell_type":"markdown","metadata":{"id":"mu-ilRKBfHak"},"source":["## Computing the score\n","\n","Now, we effectively test our translator and compute the score. \n","\n","To do that, we compute a score on 3K generated samples.\n","\n","Since computing the score directly on 3K batches could give us some problems in Colab, it is computed on batches of 300 samples each.\n","\n","Then, the total score computed as the average between batches.  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":243985,"status":"ok","timestamp":1686336402325,"user":{"displayName":"Angelo Galavotti (turtleturd)","userId":"13066918554475446773"},"user_tz":-120},"id":"WBS-e49ifFn0","outputId":"f4cfba52-2692-49cc-d615-58cfc458c78a"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","====BATCH OVER=====\n","\n","Score as of batch  0 :  0.4948857841637906\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  1 :  0.5061785304182481\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  2 :  0.5058148684303929\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  3 :  0.5027345913851916\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  4 :  0.517508295140673\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  5 :  0.530376627646052\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  6 :  0.5344367026985729\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  7 :  0.5379621676018749\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  8 :  0.542301335438453\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  9 :  0.54320980641855\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  10 :  0.5395313403534979\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  11 :  0.5377743859102094\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  12 :  0.5375765857504796\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  13 :  0.5374369683136379\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  14 :  0.5370951441912087\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  15 :  0.5368290867132967\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  16 :  0.5333478463531035\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  17 :  0.5325379103235018\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  18 :  0.5322204622558182\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  19 :  0.5328991447097614\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  20 :  0.5308620255295186\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  21 :  0.5313577698465886\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  22 :  0.5300986523987387\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  23 :  0.5283960723109501\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  24 :  0.5272936979907543\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  25 :  0.5266510407918356\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  26 :  0.5270188445976258\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  27 :  0.5259018528396617\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  28 :  0.5279189246585928\n","\n","\n","\n","====BATCH OVER=====\n","\n","Score as of batch  29 :  0.5297519821991407\n","\n","\n","\n","====ALL OVER=====\n","\n","Final score:  0.5297519821991407\n"]}],"source":["score_batch_size = 100\n","total_test_size = 3000\n","score_ = 0\n","\n","for i in range(total_test_size//score_batch_size):\n","    ordered = x_test[i*score_batch_size:(i+1)*score_batch_size]\n","    shuffled = c_test[i*score_batch_size:(i+1)*score_batch_size]\n","    y_pred = translator(shuffled)\n","    b_score = 0                   # score associated with each batch\n","\n","    pred_sentences = tokenizer.sequences_to_texts(y_pred)\n","    original_sentences = tokenizer.sequences_to_texts(ordered)\n","    \n","    for j in range(score_batch_size) :         \n","      b_score += score(clean_sentence(original_sentences[j]), clean_sentence(pred_sentences[j])) \n","\n","    score_ += b_score\n","    print(\"\\n====BATCH OVER====\") \n","    print(\"Score as of batch \", i, \": \", score_/((i+1)*score_batch_size))\n","    \n","score_ = score_/total_test_size\n","print(\"\\n====ALL OVER====\") \n","print(\"Final score: \", score_)"]},{"cell_type":"markdown","metadata":{"id":"xeBT5m40127U"},"source":["# Conclusion\n","The model obtains average performance.\n","Parameter tuning such as:\n","- increasing the attention heads\n","- increase the dropout rate\n","- increasing the model size\n","\n","Led to similar or lower scores. "]},{"cell_type":"markdown","metadata":{"id":"FR6aGNUyJp2X"},"source":["### Previous attempts \n","In the previous iteration, I tried using a stack of LSTM layers in an encoder/decoder structure, using a context vector to communicate between the two. The model also made use of teacher forcing. \n","\n","The result provided by this architecture were unsatisfying, with a very below average score, presumably because the model failed to capture the underlying relationship between sequences during training. \n","\n","This led to the adoption of the transformer model. "]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"00159a7140a845ff90d51f0b380e2561":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02fe7f98f5084e71865c29839a9eb485":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"053255074eaf4e6b981d3b6365b5043f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_39cd88457a5b4825b2d714337617dab5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f24d7234a8fc47bba285ae276173598c","value":1}},"070b38411aca4d61b27e92ff013e54f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0fe9606754f846dca2a9529c1c23afd9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f45e946fbf34b49a93b1816b36ca060","placeholder":"​","style":"IPY_MODEL_978e8855a74b42caa003ce41eb3b8360","value":"100%"}},"11dc6019491547368e0ec5d969621b4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1719c3c00e8148e3bed47fa7fe235068":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17fca631b9e845729fb1e3d00ceff408":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0fe9606754f846dca2a9529c1c23afd9","IPY_MODEL_053255074eaf4e6b981d3b6365b5043f","IPY_MODEL_1e456f0222cd4152a8603e2f4bef9f71"],"layout":"IPY_MODEL_3471275787d848c7a54b53ef672d1d74"}},"1e456f0222cd4152a8603e2f4bef9f71":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8649d0e7a35e4cb684931179ebe6b5a4","placeholder":"​","style":"IPY_MODEL_11dc6019491547368e0ec5d969621b4e","value":" 1/1 [00:00&lt;00:00, 12.00it/s]"}},"25283ef15961416fa6d21875ea0bce97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26b6c357556240848527b759e6916ad4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cedea08ec76d4f5c9936f2839e5ecd6e","placeholder":"​","style":"IPY_MODEL_b05587382e6a441dad04c47c7a37afa3","value":" 1.66k/1.66k [00:00&lt;00:00, 89.6kB/s]"}},"3471275787d848c7a54b53ef672d1d74":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35fb8d8b4d464afb9e86e8734e686c6d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39cd88457a5b4825b2d714337617dab5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3df2eb52e166436e8963c644518768cc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"451abe63d0084d7f9415e15efd33d931":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53f4ddf490db4b76b9956e3f6ebde211","placeholder":"​","style":"IPY_MODEL_070b38411aca4d61b27e92ff013e54f5","value":"Downloading metadata: 100%"}},"4998c41faaff4764b0ff4e8e4215e303":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59875cf6636947df9597b2eadca89607","placeholder":"​","style":"IPY_MODEL_ceb18602d4d942c188b40309b02a7121","value":"Downloading builder script: 100%"}},"4b4d882394a94f0aaa580f9040e89710":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e8d2888553948e5b678ef9ce61d9e0b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5064e382022d4e8b97f19a6547fc1223":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53f4ddf490db4b76b9956e3f6ebde211":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54f6c2774a2d43739754730ba19d0e18":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_be36d1bc0e924bad872ea4a9d103f3c2","IPY_MODEL_f6bdf604c22d47e583328d53771c02db","IPY_MODEL_26b6c357556240848527b759e6916ad4"],"layout":"IPY_MODEL_1719c3c00e8148e3bed47fa7fe235068"}},"56cd0d1c2d1d45b88234f75ac59d028f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab575a21d9e54d9fa3f218ba2937d33d","placeholder":"​","style":"IPY_MODEL_5732418d14a24287a524fbb74dfb8bd6","value":" 35.9k/35.9k [00:00&lt;00:00, 1.37MB/s]"}},"5732418d14a24287a524fbb74dfb8bd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59875cf6636947df9597b2eadca89607":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f33bc1eb44141528d91eddf47d4ae4d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6325f02f746a4b50a2ff6a5ae9ea3ba1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d45feda283e46e2877370f3b0b84d2d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6e11afe33fa4473bc0e5fd0c1b6de54","max":235072360,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a5d5e0994ea3465498b5e94b9fd37168","value":235072360}},"717bca4b98ee4577aa6d23d93271de30":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3df2eb52e166436e8963c644518768cc","placeholder":"​","style":"IPY_MODEL_25283ef15961416fa6d21875ea0bce97","value":" 30.4k/30.4k [00:00&lt;00:00, 1.11MB/s]"}},"7d43bb04fefa4589a356665490fa74ef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f45e946fbf34b49a93b1816b36ca060":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8649d0e7a35e4cb684931179ebe6b5a4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b218b93aa7b4dd2b9c0b84345deffcc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"947ee1e30b9d4c0fa70481e7095d6418":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"965c1953e254441e86dce8337baccc95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b43aa0e9e21d4da0a92da714f97a2536","placeholder":"​","style":"IPY_MODEL_5f33bc1eb44141528d91eddf47d4ae4d","value":"Downloading: 100%"}},"96d90639bd464b989a030ad8e203ab91":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"978e8855a74b42caa003ce41eb3b8360":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a48249ce08784da38c7eb20c04c85cd1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d43bb04fefa4589a356665490fa74ef","placeholder":"​","style":"IPY_MODEL_ed355d7b2ab54bdbada7ea9862826a7c","value":"Downloading readme: 100%"}},"a5d5e0994ea3465498b5e94b9fd37168":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a96af45ce82c4a8f9867d44dbde6600e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f99e102cce8548dfaacd0c8a3f5f7b68","placeholder":"​","style":"IPY_MODEL_02fe7f98f5084e71865c29839a9eb485","value":" 16.3k/16.3k [00:00&lt;00:00, 991kB/s]"}},"ab575a21d9e54d9fa3f218ba2937d33d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b05587382e6a441dad04c47c7a37afa3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b43aa0e9e21d4da0a92da714f97a2536":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5f89a9c0d6f427fadfb802dba48a38e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6bb330ba0254b2dbb415392553f7c5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b959770d35844c56afa4d8cabc229120":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_451abe63d0084d7f9415e15efd33d931","IPY_MODEL_e67ecd1c2d2c4bd09b69a2ecae966d00","IPY_MODEL_717bca4b98ee4577aa6d23d93271de30"],"layout":"IPY_MODEL_6325f02f746a4b50a2ff6a5ae9ea3ba1"}},"b960f44010e840a3a41975adbb4fcb87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_be342c8725bc45df80c0b4645028453c","max":35871,"min":0,"orientation":"horizontal","style":"IPY_MODEL_96d90639bd464b989a030ad8e203ab91","value":35871}},"be342c8725bc45df80c0b4645028453c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be36d1bc0e924bad872ea4a9d103f3c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b218b93aa7b4dd2b9c0b84345deffcc","placeholder":"​","style":"IPY_MODEL_bff0c2ee92f04b0b8f89644c7dc360ba","value":"Downloading: 100%"}},"bff0c2ee92f04b0b8f89644c7dc360ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ceb18602d4d942c188b40309b02a7121":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ced176bcea814fdfbe915340d327ebc2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cedea08ec76d4f5c9936f2839e5ecd6e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfdeecd47cb44a1a9af9b48770f08846":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ced176bcea814fdfbe915340d327ebc2","placeholder":"​","style":"IPY_MODEL_f94d31095cd34f4caa045c51898a2632","value":" 235M/235M [00:15&lt;00:00, 17.2MB/s]"}},"d9bb2f2922504071bccc82fd57cc34e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a48249ce08784da38c7eb20c04c85cd1","IPY_MODEL_f975205ff20e482b8850b51bdcaefe1d","IPY_MODEL_a96af45ce82c4a8f9867d44dbde6600e"],"layout":"IPY_MODEL_35fb8d8b4d464afb9e86e8734e686c6d"}},"e455328f873a438b99b485c2649e0109":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_965c1953e254441e86dce8337baccc95","IPY_MODEL_6d45feda283e46e2877370f3b0b84d2d","IPY_MODEL_cfdeecd47cb44a1a9af9b48770f08846"],"layout":"IPY_MODEL_b5f89a9c0d6f427fadfb802dba48a38e"}},"e49a61dae69644c7b361cef046df71c3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e67ecd1c2d2c4bd09b69a2ecae966d00":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_947ee1e30b9d4c0fa70481e7095d6418","max":30394,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5064e382022d4e8b97f19a6547fc1223","value":30394}},"ed355d7b2ab54bdbada7ea9862826a7c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f24d7234a8fc47bba285ae276173598c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f6bdf604c22d47e583328d53771c02db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e49a61dae69644c7b361cef046df71c3","max":1660,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b6bb330ba0254b2dbb415392553f7c5b","value":1660}},"f6e11afe33fa4473bc0e5fd0c1b6de54":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f94d31095cd34f4caa045c51898a2632":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f975205ff20e482b8850b51bdcaefe1d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_00159a7140a845ff90d51f0b380e2561","max":16258,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e8d2888553948e5b678ef9ce61d9e0b","value":16258}},"f99e102cce8548dfaacd0c8a3f5f7b68":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe67467be06a4c00872c054f062b51be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4998c41faaff4764b0ff4e8e4215e303","IPY_MODEL_b960f44010e840a3a41975adbb4fcb87","IPY_MODEL_56cd0d1c2d1d45b88234f75ac59d028f"],"layout":"IPY_MODEL_4b4d882394a94f0aaa580f9040e89710"}}}}},"nbformat":4,"nbformat_minor":4}
